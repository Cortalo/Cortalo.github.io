<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Topics in The Theory of Random Noise 01" /><meta property="og:locale" content="en" /><meta name="description" content="From book_topics_in_the_theory_of_random_noise" /><meta property="og:description" content="From book_topics_in_the_theory_of_random_noise" /><link rel="canonical" href="/posts/topics-in-the-theory-of-random-noise-01/" /><meta property="og:url" content="/posts/topics-in-the-theory-of-random-noise-01/" /><meta property="og:site_name" content="Looooooong" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-12-20T10:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Topics in The Theory of Random Noise 01" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-26T15:49:11+00:00","datePublished":"2022-12-20T10:00:00+00:00","description":"From book_topics_in_the_theory_of_random_noise","headline":"Topics in The Theory of Random Noise 01","mainEntityOfPage":{"@type":"WebPage","@id":"/posts/topics-in-the-theory-of-random-noise-01/"},"url":"/posts/topics-in-the-theory-of-random-noise-01/"}</script><title>Topics in The Theory of Random Noise 01 | Looooooong</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Looooooong"><meta name="application-name" content="Looooooong"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">Looooooong</a></div><div class="site-subtitle font-italic">Don't confuse them, if you cannot convince them.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/github_username" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['helong_ms','outlook.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Topics in The Theory of Random Noise 01</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Topics in The Theory of Random Noise 01</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1671530400" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Dec 20, 2022 </em> </span> <span> Updated <em class="" data-ts="1672069751" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Dec 26, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://twitter.com/username">Long</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1828 words"> <em>10 min</em> read</span></div></div></div><div class="post-content"><p>From <a href="https://archive.org/details/stratonovich-topics-in-the-theory-of-random-noise-vol-1">book_topics_in_the_theory_of_random_noise</a></p><h1 id="chapter-1-random-functions-and-their-statistical-characteristics">Chapter 1: Random Functions and Their Statistical Characteristics</h1><h2 id="1-random-variables"><span class="mr-2">1. Random Variables</span><a href="#1-random-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>A random variable $\xi$ should have definition mean of any function \(\langle f(\xi)\rangle_{\xi}\)</p>\[\langle\xi\rangle_{\xi} = \lim_{n\to\infty} \dfrac{\xi_1 + \xi_2 + \dots + \xi_n}{n} = \lambda()\] \[\langle\xi^2\rangle_{\xi} = \lim_{n\to\infty} \dfrac{\xi_1^2 + \xi_2^2 + \dots + \xi_n^2}{n} = \lambda()\] \[\langle f(\xi)\rangle_{\xi} = \lim_{n\to\infty} \dfrac{f(\xi_1) + f(\xi_2) + \dots + f(\xi_n)}{n} = \lambda()\] \[\langle f(x,\xi)\rangle_{\xi} = \lim_{n\to\infty} \dfrac{f(x,\xi_1) + f(x,\xi_2) + \dots + f(x,\xi_n)}{n} = \lambda(x)\]<ul><li>Derivitive: \(\dfrac{d}{dx}\langle f(x,\xi)\rangle_{\xi} = \langle \dfrac{\partial}{\partial x} f(x,\xi)\rangle_{\xi}\)</ul>\[\begin{align} &amp; \dfrac{d}{dx} \langle f(x,\xi)\rangle_{\xi} = \lim_{\Delta x \to 0}\dfrac{\langle f(x + \Delta x,\xi)\rangle_{\xi} - \langle f(x,\xi)\rangle_{\xi}}{\Delta x}\\ =&amp; \lim_{\Delta x \to 0} \dfrac{\lim_{n\to\infty} \dfrac{f(x+\Delta x,\xi_1) + \dots + f(x+\Delta x, \xi_n)}{n} - \lim_{n\to\infty} \dfrac{f(x,\xi_1)+\dots+f(x,\xi_n)}{n}}{\Delta x}\\ = &amp; \lim_{\Delta x \to 0} \Big[ \lim_{n\to\infty}\dfrac{f(x+\Delta x,\xi_1)+\dots + f(x+\Delta x, \xi_n)}{n\Delta x} - \lim_{n\to\infty} \dfrac{f(x,\xi_1)+\dots + f(x,\xi_n)}{n\Delta x} \Big]\\ = &amp; \lim_{\Delta x \to 0} \lim_{n\to\infty} \dfrac{(f(x+\Delta x,\xi_1)-f(x,\xi_1)) + \dots + (f(x+\Delta x,\xi_n)-f(x,\xi_n))}{n\Delta x}\\ \doteq &amp; \lim_{n\to\infty}\lim_{\Delta x\to 0} \dfrac{(f(x+\Delta x,\xi_1)-f(x,\xi_1)) + \dots + (f(x+\Delta x,\xi_n)-f(x,\xi_n))}{n\Delta x}\\ = &amp; \lim_{n\to\infty} \dfrac{\dfrac{\partial}{\partial x}f(x,\xi_1)+\dots \dfrac{\partial}{\partial x}f(x,\xi_n)}{n}\\ = &amp; \langle \dfrac{\partial}{\partial x}f(x,\xi)\rangle_{\xi} \end{align}\]<ul><li><p>Integration: \(\int_{a}^{b}\langle f(x,\xi)\rangle_{\xi}dx = \langle\int_{a}^{b} f(x,\xi)dx\rangle_{\xi}\)</p><li><p>Assume we have a random variable \(\eta\), but it is actually fully determined by another random variable \(\xi\), \(\eta = g(\xi)\).</p></ul>\[\begin{align} &amp;\langle f(\eta)\rangle_{\eta} = \lim_{n\to\infty} \dfrac{f(\eta_1)+\dots+f(\eta_n)}{n} = \lim_{n\to\infty} \dfrac{f(g(\xi_1))+\dots+f(g(\xi_n))}{n}\\ =&amp; \langle f(g(\xi))\rangle_{\xi} \end{align}\]<p>so, if \(\eta = g(\xi)\), then \(\langle f(\eta)\rangle_{\eta} = \langle f(g(\xi))_{\xi}\), or \(\langle f(g(\xi))\rangle_{g(\xi)} = \langle f(g(\xi))\rangle_{\xi}\)</p><p>if we define function</p>\[\theta(z) = \begin{cases} 1 &amp; \text{ for } \quad z &gt; 0,\\ 0 &amp; \text{ for } \quad z \le 0 \end{cases}\]<p><img data-src="/assets/img/2022-12-20-topics-in-the-theory-of-random-noise-01/001.png" style="width:50%;height:50%;" data-proofer-ignore></p><p>Then we have <em>distribution function</em></p>\[P\{\xi &lt; x\} = F_{\xi}(x) = \langle\theta(x-\xi)\rangle_\xi\]<p>and the probability density function</p>\[\begin{align} w_\xi(x) &amp;= \dfrac{d}{dx} F_\xi(x) = \dfrac{d}{dx}\langle\theta(x-\xi)\rangle_\xi = \langle\dfrac{\partial}{\partial x}\theta(x-\xi)\rangle_\xi = \langle\delta(x-\xi)\rangle_\xi \end{align}\]<p>this can be used to calculate cany \(\langle f(\xi)\rangle\)</p>\[\begin{align} \langle f(\xi)\rangle_{\xi} &amp;= \langle \int_{-\infty}^{\infty} f(x)\delta(x-\xi)dx \rangle_{\xi} = \int_{-\infty}^{\infty}\langle f(x)\delta(x-\xi)\rangle_{\xi} dx\\ &amp;= \int_{-\infty}^{\infty} f(x)\langle\delta(x-\xi)\rangle_{\xi} dx = \int_{-\infty}^{\infty} f(x)w_{\xi}(x)dx \end{align}\]<p>Next, we show how the probability density behaves under transformations of the original random variable \(\xi\). Let the new randon variable \(\eta\) be defined by</p>\[\eta = g(\xi)\]<p>then</p>\[\begin{align} w_{\eta}(x) &amp;= \langle\delta(x-\eta)\rangle_{\eta} = \langle\delta(x-g(\xi))\rangle_{\xi}\\ &amp;= \int_{-\infty}^{\infty} \delta(x-g(\xi)) w_{\xi}(\xi)d\xi \end{align}\]<p>If \(g(\xi)\) is monotone, it has a unique inverse function \(\xi = g^{-1}(\eta)\)</p>\[\begin{align} w_{\eta}(x) &amp;= \int_{-\infty}^{\infty} \delta(x-g(g^{-1}(\eta)))w_{\xi}(g^{-1}(\eta))d(g^{-1}(\eta))\\ &amp;= \int_{-\infty}^{\infty} \delta(x-\eta)w_{\xi}(g^{-1}(\eta)) \dfrac{dg^{-1}(\eta)}{d\eta}d\eta\\ &amp;= w_{\xi}(g^{-1}(x))\dfrac{d g^{-1}(\eta)}{d\eta}\bigg|_{\eta=x}\\ &amp;= w_{\xi}(\xi) \cdot (\dfrac{dg}{d\xi})^{-1}\bigg|_{\xi=g^{-1}(x)} \end{align}\]<p>If there are multiple \(g(\xi_i) = x\)</p>\[w_{\eta}(x) = \sum_{i}\Bigg[ w_{\xi}(\xi_i)\cdot (\dfrac{dg}{d\xi})\bigg|_{\xi=\xi_i} \Bigg]\]<p>Define characteristic function</p>\[\Theta_{\xi}(u) = \langle e^{iu\xi}\rangle_{\xi} = \int e^{iu\xi}w(\xi)d\xi\]<p>this is similar to Fourier transform with only a sign different</p>\[w(\xi) = \dfrac{1}{2\pi}\int \Theta_{\xi}(u)e^{-iu\xi}du\]<p>The moments \(m_n = \langle \xi^n\rangle_{\xi}\) can be calculated as</p>\[\begin{align} &amp;\dfrac{1}{i^n}\dfrac{d^n \Theta_{\xi}(u)}{du^n}\bigg|_{u=0} = \dfrac{1}{i^n} \langle \dfrac{d^n}{du^n} e^{iu\xi} \rangle_{\xi}\bigg|_{u=0}\\ =&amp; \dfrac{1}{i^n}\langle i^n \xi^n e^{iu\xi}\rangle_{\xi}\bigg|_{u=0} = \langle \xi^n\rangle_{\xi} \end{align}\]<p>we can write \(\Theta_{\xi}(u)\) as a Maclaurin series:</p>\[\Theta_\xi(u) = 1 + \sum_{n=1}^{\infty} \dfrac{(iu)^n}{n!}m_n\]<p>For a variaty of reasons, it is more convenient to characterize a random variable not by its moments, but by its <em>cumulants</em> (or <em>semi-invariants</em>) \(k_n\), defined by the relation</p>\[\Theta_{\xi}(u) = \exp \bigg\{ \sum_{n=0}^{\infty} \dfrac{(iu)^n}{n!}k_n \bigg\}\]<p>using \(e^x = 1 + x + \dfrac{x^2}{2!} + \dfrac{x^3}{3!} + \dots\), comparing the two equations, we have, for example</p>\[\Theta_{\xi}(u) = 1 + \dfrac{iu}{1!}k_1 + \dfrac{(iu)^2}{2!}k_2 + \dfrac{(iu)^2}{2}k_1^2\]<p>we can obtain the following formulas relating the moments and the cumulants:</p>\[\begin{align} k_1 &amp;= m_1\\ k_2 &amp;= m_2 - m_1^2\\ k_3 &amp;= m_3 - 3m_1 m_2 + 2m_1^2\\ k_4 &amp;= m_4 - 3m_2^2 - 4m_1 m_3 + 12 m_1^2 m_2 - 6m_1^4 \end{align}\]<p>it shows</p>\[k_2 = \langle (\xi-\langle\xi\rangle)^2\rangle, \quad k_3 = \langle (\xi-\langle\xi\rangle)^3\rangle\]<p>The quantity \(k_2 = \langle\xi^2\rangle - \langle\xi\rangle^2\) is called the <em>variance</em> (or <em>dispersion</em>) of \(\xi\), and is denoted by</p>\[\mathbf{D}\xi = \langle \xi^2\rangle - \langle\xi\rangle^2\]<p>There are also defition for <em>standard deviation</em></p>\[\sigma(\xi) = [\mathbf{D}\xi]^{1/2}\]<h2 id="2-correlation-between-random-variables"><span class="mr-2">2. Correlation Between Random Variables</span><a href="#2-correlation-between-random-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Suppose we have \(r\) random variables \(\xi_1, \dots,\xi_r\), they are fully depends on a unknown random variable \(\zeta\)</p>\[\begin{align} \xi_1 &amp;= g_1(\zeta)\\ \xi_2 &amp;= g_2(\zeta)\\ &amp; \dots \\ \xi_r &amp;= g_r(\zeta) \end{align}\]<p>then</p>\[\langle f(\xi_1,\dots,\xi_n)\rangle_{\zeta} = \lim_{n\to\infty} \dfrac{f(g_1(\zeta_1),\dots,g_r(\zeta_1))+\dots + f(g_1(\zeta_n)+\dots + g_r(\zeta_n))}{n}\]<p>The random variables \(\xi_1,\dots,\xi_r\) are completely characterized by the <em>(joint) \(r\)-dimensional probability density</em></p>\[w_{\xi_1,\dots,\xi_r}(x_1,\dots,x_r) = \langle \delta(\xi_1-x_1)\dots \delta(\xi_r - x_r) \rangle\]<p>the mean value can be calculated as</p>\[\langle f(\xi_1,\dots,\xi_r) \rangle = \int \dots \int f(\xi_1,\dots,\xi_r) w(\xi_1,\dots,\xi_r) d\xi_1 \dots d\xi_r\]<p>In the absence of knowledge of the actual realization (i.e., observed value) of \(\xi_2\), the random variable \(\xi_1\) has the probility density</p>\[w(\xi_1) = \int w(\xi_1,\xi_2)d \xi_2\]<p>but</p>\[w(\xi_1 | \xi_2) = \dfrac{w(\xi_1,\xi_2)}{\int w(\xi_1,\xi_2)d\xi_1}\]<p>If no information about \(\xi_1\) is gained, regardless of the observed value of \(\xi_2\), which means</p>\[\begin{align} w(\xi_1 | \xi_2) &amp;= w(\xi_1)\\ w(\xi_1, \xi_2) &amp;= w(\xi_1)w(\xi_2) \end{align}\]<p>If \(\xi_1\) and \(\xi_2\) are <em>completely correlated</em></p>\[w(\xi_1,\xi_2) = \delta[\xi_1 - f(\xi_2)]w(\xi_2)\]<p>In general</p>\[\begin{align} w(\xi_1,\dots,\xi_k | \xi_{k+1},\dots,\xi_r) &amp;= \dfrac{w(\xi_1,\dots,\xi_r)}{w(\xi_{k+1},\dots,\xi_r)}\\ w(\xi_1,\dots,\xi_k) &amp;= \int \cdots \int w(\xi_1,\dots,\xi_r)d \xi_{k+1}\dots d\xi_{r} \end{align}\]<p>The <em>covariance</em> (synonymously, <em>cross correlation</em> or <em>double correlation</em>) describe the degree of statistical dependence between random variables.</p>\[\mathbf{K}[\xi_1,\xi_2] = \langle \xi_1 \xi_2 \rangle - \langle \xi_1 \rangle \langle \xi_2 \rangle\]<p>If \(\xi_1\) and \(\xi_2\) are independent, we have</p>\[\begin{align} \langle \xi_1 \xi_2 \rangle &amp;=\langle \xi_1 \rangle\langle \xi_2 \rangle \mathbf{K}[\xi_1,\xi_2] &amp;= 0 \end{align}\]<p>By definition, the covariance of a random variable with itself is just its variance</p>\[\mathbf{K}[\xi,\xi] = \mathbf{D}\xi\]<p>Sometimes, instead of \(\mathbf{K}[\xi_1,\xi_2]\)m it is convenient to consider the dimensionless quantity</p>\[R_2 \equiv R = \dfrac{\mathbf{K}[\xi_1,\xi_2]}{\sigma(\xi_1)\sigma(\xi_2)}\]<p>The quantity reduces to unity when the random variables coincide, and is called the <em>correlation coefficient</em> of \(\xi_1\) and \(\xi_2\).</p><p>Besides double correlatoins, there are multiple correlations of higher orders. For example,</p>\[\langle \xi_1\xi_2\xi_3 \rangle - \langle \xi_1 \rangle\langle \xi_2 \rangle\langle \xi_3 \rangle\]<p>But the triple correlation is defined as</p>\[\begin{align} \mathbf{K}[\xi_1,\xi_2,\xi_3] =\langle \xi_1 \xi_2 \xi_3 \rangle -\langle \xi_1 \rangle \mathbf{K}[\xi_2,\xi_3] -\langle \xi_2 \rangle \mathbf{K}[\xi_1,\xi_2] -\langle \xi_3 \rangle \mathbf{K}[\xi_1,\xi_2] -\langle \xi_1 \rangle\langle \xi_2 \rangle\langle \xi_3 \rangle \end{align}\]<p>Chatacteristic function</p>\[\begin{align} \Theta(u_1,\dots,u_r) &amp;=\langle \exp i(u_1 \xi_1 + \dots + u_r \xi_r) \rangle\\ \langle \xi_1,\dots,\xi_r \rangle &amp;= \dfrac{1}{i^r} \dfrac{\partial^r \Theta(u_1,\dots,r_r)}{\partial u_1 \dots \partial u_r} \bigg|_{u_1 = \dots = u_r = 0}\\ \mathbf{K}[\xi_1,\dots,\xi_r] &amp;= \dfrac{1}{i^r}\dfrac{\partial^r \ln \Theta(u_1,\dots,u_r)}{\partial u_1 \dots \partial u_r} \bigg|_{u_1=\dots=u_r=0} \end{align}\]<h2 id="3-random-functions"><span class="mr-2">3. Random Functions</span><a href="#3-random-functions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Next, we consider a <em>random function</em> \(\xi(t)\) of a single real argument \(t\) (the time) which varies over the interval \([0, T]\), say.</p><p>If we take \(r\) fixed values \(t_1,\dots,t_r\) from the interval \([0,T]\), then the values \(\xi(t_1),\dots,\xi(t_r)\) constitute a family of random variables.</p>\[w_r(x_1,\dots,x_r;t_1,\dots,t_r) = \langle \delta[x_1-\xi(t_1)]\dots\delta[x_r-\xi(t_r)] \rangle\]<p>The characteristic functions:</p>\[\begin{align} \Theta(u_1; t_1) &amp;= \langle e^{i u_1 \xi(t_1)}\\ \Theta(u_1, u_2; t_1, t_2) &amp;= \langle e^{i u_1 \xi(t_1)+iu_2\xi(t_2)} \rangle\\ &amp;\dots \end{align}\]<p>to the limit we get <em>characteristic functional</em></p>\[\Theta[u(t)] = \bigg\langle \exp \bigg[i\int u(t)\xi(t) dt\bigg] \bigg\rangle\]<p>The each characteristic function can be obtained by using</p>\[u(t) = \sum u_{\alpha} \delta(t-t_{\alpha})\]<p>The term <em>random process</em> (or simply <em>process</em>) is used as a synonym for a random function of time.</p><p>In its general from, a random process cannot be described by a finite number of functions of a finite number of variables, and hence a random process is either characterized by an infinite sequence of functions or by a functional. It is preferable to consider a sequence of functions such that the functions of higher order do not repeat the information contained in the preceding functions, but instead carry only new information. Therefore, we now introduce another method of describing random processes, which has this and other advantages.</p><p>The mean values</p>\[\langle \xi(t_1)\dots\xi(t_r) \rangle = m_r(t_1,\dots,t_r)\]<p>are called moment functions, and the infinite sequence of moment functions</p>\[m_1(t_1),\quad m_2(t_1,t_2),\quad m_3(t_1,t_2,t_3), \dots\]<p>gives an exhaustive description of the random process \(\xi(t)\). It is even better to characterize the random process \(\xi(t)\) by the sequence of <em>correlation functions</em></p>\[k_1(t_1),\quad k_2(t_1,t_2),\quad k_3(t_1,t_2,t_3), \quad\dots\]<p>which are defined as the multiple correlations</p>\[k_r(t_1,\dots,t_r) \equiv \mathbf{K}[\xi(t_1),\dots,\xi(t_r)]\]<p>regarded as functions of the time \(t_1,\dots,t_r\). The correlation functions, just like the moment functions, are symmetric functions of their arguments.</p><p>The vast majority of random processes encountered in radio physics have the property that when the time \(t_1,\dots,t_r\) are moved apart, the correlation between the corresponding values of the process falls off, i.e., the correlation functions goes to zero, which is very convenient.</p><p>If we know the moment functions or the correlation functions, we can find the other characteristics of a random process, in particular, its characteristic functions or probability densities.</p><p>Using formula \(\langle \xi_1,\dots,\xi_r \rangle = \dfrac{1}{i^r} \dfrac{\partial^r \Theta(u_1,\dots,r_r)}{\partial u_1 \dots \partial u_r} \bigg\vert_{u_1 = \dots = u_r = 0}\), we can write the characteristic function as a multidimentional Taylor’s series:</p>\[\Theta_r(u_1,\dots,u_r;t_1,\dots,t_r) = 1 + \sum_{s=1}^{\infty} \dfrac{s!}{i^s}\sum_{\alpha,\dots,\omega=1}^{r}m_s(t_{\alpha},\dots,t_{\omega})u_{\alpha}\dots u_{\omega}\]<p>In just the same way</p>\[\Theta_r(u_1,\dots,u_r;t_1,\dots,t_r) = \exp \big\{\sum_{s=1}^{\infty} \dfrac{i^s}{s!} \sum_{\alpha,\dots,\omega=1}^{r} k_s(t_{\alpha,\dots,t_{\omega}})u_{\alpha}\dots u_{\omega}\big\}\]<p>and</p>\[\Theta[u(t)] = \exp\big\{ \sum_{s=1}^{\infty} \dfrac{i^s}{s!} \int \cdots \int k_s(t_1,\dots,t_s) u(t_1) \dots u(t_s) d t_1 \dots d t_s \big\}\]<p>Because of the special role played by moment functions and correlation functions, we give the following formulas relating them:</p>\[\begin{align} m_1(t_1) &amp;= k_1(t_1)\\ m_2(t_1,t_2) &amp;= k_2(t_1,t_2) + k_1(t_1)k_1(t_2)\\ m_3(t_1,t_2,t_3) &amp;= k_3(t_1,t_2,t_3) + 3\{k_1(t_1)k_2(t_2,t_3)\}_s + k_1(t_1)k_1(t_2)k_1(t_3)\\ m_4(t_1,t_2,t_3,t_4) &amp;= k_4(t_1,t_2,t_3,t_4) + 3\{k_2(t_1,t_2)k_2(t_3,t_4)\}_s + 4\{k_1(t_1)k_3(t_2,t_3,t_4)\}_s + 6\{k_1(t_1)k_1(t_2)k_2(t_3,t_4)\}_s + k_1(t_1)k_1(t_2)k_1(t_3)k_1(t_4) \end{align}\]<p>Here, the symbol \(\{\dots\}_s\) denotes the operation of symmetrizing the expression in brackets with respect to all its arguments.</p><p>It seems like if \(k_1 = 0\), then the correlation functions are the same as the central moments. But it is not true. The difference begins with \(k_4\)</p><h1 id="chapter-2-stationary-random-processes-and-spectral-densities">Chapter 2: Stationary Random Processes and Spectral Densities</h1><p>A random process is said to be stationary (in the strict sense) if its statistical characteristics are invariant under time shifts, i.e., if they reamin the same when \(t\) is replaced by \(t+a\), where \(a\) is arbitrary. Then, the probability densities \(w_n(\xi_1,\dots,\xi_n;t_1,\dots,t_n)\) together with the moment and correlation functions \(m_n(t_1,\dots,t_n)\) and \(k_n(t_1,\dots,t_n)\) do not depend on the absolute position of the points \(t_1,\dots,t_n\) on the times axis, but only on their relative configuration.</p>\[k_n(t_1,\dots,t_n) = k_n(0,t_2-t_1,\dots,t_n-t_1) = k_n'(t_2-t_1,\dots,t_n-t_1)\]<p>for which we introduce the special notation</p>\[k_2(t_1,t_2) = \langle \xi(t_1)\xi(t_2) \rangle - \langle \xi(t_1) \rangle \langle \xi(t_2) \rangle = k(t_2-t_1)\]<p>where \(k(\tau) = k(-\tau)\). If the process has zero mean</p>\[k(\tau) = \langle \xi(0)\xi(\tau) \rangle\]<p>We can also write \(k(\tau)\) in the form</p>\[k(\tau) = \sigma^2 R(\tau)\]<p>where \(\sigma = \sigma[\xi(t)] = \sqrt{k(0)}\) is the standard deviation of \(\xi(t)\), and \(R(\tau) = k(\tau)/\sigma^2\) is the dimensionless, normalized correlation coefficient, with the property that \(R(0) = 1\).</p><p>Next, we introduce the important concept of the <em>(power) spectral density</em> \(S[\xi;\omega]\) of a stationary random process \(\xi(t)\):</p>\[S[\xi;\omega] = 2\int_{-\infty}^{\infty} e^{i\omega \tau} \langle \xi \xi_\tau \rangle d\tau = 4 \int_{0}^{\infty} \cos \omega \tau \langle \xi \xi_\tau \rangle d\tau\]<p>Here, and subsequently, the subscript \(\tau\) on a function like \(\xi_\tau\), denotes a shift of the argument by a amount \(\tau\), i.e., \(\xi_\tau = \xi(t+\tau)\). For a process with zero mean value, \(S[\xi;\omega]\) is the Fourier transform of the correlation function:</p>\[S[\xi;\omega] = 2\int_{-\infty}^{\infty} e^{i\omega \tau} k(\tau) d\tau\]<p>In the general case, where \(\langle \xi \rangle = m\) is not zero</p>\[\begin{align} S[\xi-m;\omega] &amp;= 2\int_{-\infty}^{\infty} e^{i\omega\tau} k(\tau)d\tau\\ S[\xi;\omega] &amp;= S[\xi-m;\omega] + 4\pi m^2 \delta(\omega) \end{align}\]<p>The inverse formula gives</p>\[\sigma^2(\xi) = k(0) = \dfrac{1}{2\pi} \int_{0}^{\infty} S[\xi-m;\omega]d\omega\]</div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/math/'>math</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/math/" class="post-tag no-text-decoration" >math</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Topics+in+The+Theory+of+Random+Noise+01+-+Looooooong&url=%2Fposts%2Ftopics-in-the-theory-of-random-noise-01%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Topics+in+The+Theory+of+Random+Noise+01+-+Looooooong&u=%2Fposts%2Ftopics-in-the-theory-of-random-noise-01%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=%2Fposts%2Ftopics-in-the-theory-of-random-noise-01%2F&text=Topics+in+The+Theory+of+Random+Noise+01+-+Looooooong" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/analog-circuits/">Analog Circuits</a><li><a href="/posts/signal-and-system-01/">Signal And System 01</a><li><a href="/posts/integration-by-substitution/">Integration by Subsitution</a><li><a href="/posts/signal-and-system-explain/">Signal And System Explain</a><li><a href="/posts/engineering-mathematics/">Engineering Mathematics</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/analog/">analog</a> <a class="post-tag" href="/tags/pll/">pll</a> <a class="post-tag" href="/tags/fourier-analysis/">fourier-analysis</a> <a class="post-tag" href="/tags/scheme/">scheme</a> <a class="post-tag" href="/tags/sicp/">sicp</a> <a class="post-tag" href="/tags/calculus/">calculus</a> <a class="post-tag" href="/tags/cs61a/">cs61a</a> <a class="post-tag" href="/tags/em/">EM</a> <a class="post-tag" href="/tags/probability/">probability</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/engineering-mathematics-explanation/"><div class="card-body"> <em class="small" data-ts="1690099200" data-df="ll" > Jul 23, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Engineering Mathematics Explanation</h3><div class="text-muted small"><p> First-Order First-Degree ODE Useful Formulas Integrations \[\begin{align} &amp;amp; \int x^n dx = \dfrac{x^{n+1}}{n+1} + C\\ &amp;amp; \int \dfrac{1}{x} dx = \ln \vert x \vert + C\\ &amp;amp; \int \frac{1}{...</p></div></div></a></div><div class="card"> <a href="/posts/probability-theory-and-examples-01/"><div class="card-body"> <em class="small" data-ts="1672221600" data-df="ll" > Dec 28, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Probability: Theory and Examples 01</h3><div class="text-muted small"><p> From book_probability_theory_and_examples Measure Theory Probability Spaces Here and throughout the book, terms being defined are set in boldface. Here and in what follows, countable means fini...</p></div></div></a></div><div class="card"> <a href="/posts/measure-theory-01/"><div class="card-body"> <em class="small" data-ts="1672372800" data-df="ll" > Dec 30, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Measure Theory 01</h3><div class="text-muted small"><p> {% include embed/youtube.html id=’llnNaRzuvd4’ %} Introdution: A Non-Measurable Set Can we define a measure on \(\mathbb{R}\), such that it works on all the subsets of \(\mathbb{R}\)? (i) \(\lam...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/oscillator-phase-noise-a-tutorial/" class="btn btn-outline-primary" prompt="Older"><p>Oscillator Phase Noise: A Tutorial</p></a> <a href="/posts/probability-theory-and-examples-01/" class="btn btn-outline-primary" prompt="Newer"><p>Probability: Theory and Examples 01</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/username">Long</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/analog/">analog</a> <a class="post-tag" href="/tags/pll/">pll</a> <a class="post-tag" href="/tags/fourier-analysis/">fourier-analysis</a> <a class="post-tag" href="/tags/scheme/">scheme</a> <a class="post-tag" href="/tags/sicp/">sicp</a> <a class="post-tag" href="/tags/calculus/">calculus</a> <a class="post-tag" href="/tags/cs61a/">cs61a</a> <a class="post-tag" href="/tags/em/">EM</a> <a class="post-tag" href="/tags/probability/">probability</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
